{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tackling MNIST with just Numpy "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing dependecies\n",
    "Note: Tensorflow is imported here so that we can easily get the mnist dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "print (f'x_train shape: {x_train.shape}')\n",
    "print (f'y_train shape: {y_train.shape}')\n",
    "print (f'y_train example: {y_train[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(2,5, figsize=(12,5))\n",
    "axes = axes.flatten()\n",
    "idx = np.random.randint(0,60000,size=10)\n",
    "for i in range(10):\n",
    "    axes[i].imshow(x_train[idx[i],:].reshape(28,28), cmap='gray')\n",
    "    axes[i].axis('off') # hide the axes ticks\n",
    "    axes[i].set_title(str(int(y_train[idx[i]])), color= 'black', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Each pixel is single grayscale, meaning a value between 0 to 255.\n",
    "Normalising the inputs to a value between 0 to 1 makes the calculations later on smaller.\n",
    "This makes the gradient value closer to our weight initialization \n",
    "'''\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_train = x_train/255\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\n",
    "x_test = x_test/255\n",
    "\n",
    "def one_hot_encode_array(y:np.array):\n",
    "    '''Hot encodes the output examples.'''\n",
    "    hot_encoded = np.zeros([y.shape[0],10 ])\n",
    "    for i, x in enumerate(y):\n",
    "        hot_encoded[i][x] = 1\n",
    "    return hot_encoded\n",
    "\n",
    "y_train = one_hot_encode_array(y_train)\n",
    "y_test = one_hot_encode_array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax of vector x in a numerically stable way.\"\"\"\n",
    "    shiftx = x - np.max(x,axis=0)\n",
    "    exps = np.exp(shiftx)\n",
    "    return exps / np.sum(exps,axis=0)\n",
    "\n",
    "def d_softmax(x):\n",
    "    shiftx = x - np.max(x,axis=0)\n",
    "    exps = np.exp(shiftx)\n",
    "    return exps/(np.sum(exps,axis=0) * (1-exps/np.sum(exps,axis=0)))\n",
    "\n",
    "def relu(x):\n",
    "    x[x<0] = 0\n",
    "    return x \n",
    "\n",
    "def d_relu(x):\n",
    "    return x >0\n",
    "\n",
    "def forward_pass(a_0, w_1, w_2):\n",
    "    z_1 = w_1 @ a_0   #   N1 x 784 * 784 x m  = N1 x m\n",
    "    a_1 = relu(z_1) #  N1 x m \n",
    "    z_2 = w_2 @ a_1 #  10 x N1 * N1 x m  = 10 x m\n",
    "    a_2 = softmax(z_2) # 10 x m\n",
    "    return z_1,a_1, z_2 ,a_2\n",
    "\n",
    "def cost_function(x,y):\n",
    "    return (x - y) ** 2\n",
    "\n",
    "def d_cost_function(a_2,y):\n",
    "    return ( a_2 - y) # The 2 here is irrelavent in the grand scheme of things. This is because the learning rate will be a constant multiple as well.\n",
    "    \n",
    "def backward_pass(a_0, z_1,a_1, z_2 ,a_2, w_1,w_2, Y):\n",
    "    # Backward pass, differenciate wrt Cost function.\n",
    "    d_a2 =  d_cost_function(a_2, Y) # 10 x m\n",
    "    d_z2 = d_cost_function(a_2, Y) # 10 x m\n",
    "    d_w2 = d_z2 @ a_1.T # 10 x m * m x N1 = 10 x N1\n",
    " \n",
    "    d_a1 = w_2.T @ d_z2 # N1 x 10  * 10 x m  = N1 x m\n",
    "    d_z1 = d_a1 * d_relu(z_1) # N1 x m   N1 x m = N1 x m\n",
    "    d_w1 = d_z1 @ a_0.T # N1 x m * m x 784 = N1 x 784\n",
    "\n",
    "    assert d_w1.shape == w_1.shape, f'{d_w1.shape} {w_1.shape}'\n",
    "    assert d_w2.shape == w_2.shape, f'{d_w2.shape} {w_2.shape}'\n",
    "\n",
    "    return  d_w1 , d_w2\n",
    "\n",
    "def update_weights(w_1,w_2, d_w1 , d_w2, learning_rate, N):\n",
    "    w_1 = w_1 - learning_rate*d_w1 / N\n",
    "    w_2 = w_2 - learning_rate*d_w2 / N\n",
    "    return w_1, w_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, w_1, w_2 , epochs = 1, learning_rate=0.001):\n",
    "    for i in range(epochs):\n",
    "        N = X.shape[0]\n",
    "        a_0 = X\n",
    "        z_1, a_1, z_2 ,a_2 = forward_pass(a_0, w_1, w_2)\n",
    "        print(z_2)\n",
    "        d_w1 , d_w2 = backward_pass(a_0, z_1,a_1, z_2 ,a_2, w_1,w_2, Y)\n",
    "        w_1, w_2 = update_weights(w_1,w_2, d_w1,d_w2,learning_rate,N)\n",
    "\n",
    "    return w_1,w_2\n",
    "\n",
    "def get_prediction(a_2):\n",
    "    return np.argmax(a_2.T)\n",
    "\n",
    "def check_accuracy(X,Y ,w_1,w_2):\n",
    "    a_0 = X\n",
    "    z_1,a_1, z_2 ,a_2 = forward_pass(a_0, w_1, w_2)\n",
    "    return a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 256\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "w_1 = np.random.rand(neurons,784)\n",
    "w_2 = np.random.rand(10, neurons)\n",
    "orig_w_1 = w_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "w_1,w_2 = gradient_descent(x_train.T, y_train.T, w_1, w_2, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = check_accuracy(x_test.T,y_test.T,w_1,w_2)\n",
    "np.argmax(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_test,axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69794a4f2e6b88789417fbfa55385ccec1db84b3e27bcc17da2343fc727325cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
